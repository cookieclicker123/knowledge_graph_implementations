from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, TypeAlias
from datetime import datetime, timezone

from .enums import DataSource, RetrievalMode

# Type Aliases
VectorEmbedding: TypeAlias = List[float]
Metadata: TypeAlias = Dict[str, Any]

# Core Data Models
class Document(BaseModel):
    """Represents a single input document before processing."""
    id: str = Field(..., description="Unique identifier for the document")
    content: str = Field(..., description="Raw content of the document")
    source: DataSource = Field(..., description="Origin type of the document")
    source_uri: Optional[str] = Field(None, description="Specific URI (e.g., file path, URL)")
    metadata: Metadata = Field(default_factory=dict, description="Additional metadata")
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc), description="Timestamp of creation/ingestion")

class Chunk(BaseModel):
    """Represents a processed chunk of a document."""
    id: str = Field(..., description="Unique identifier for the chunk")
    document_id: str = Field(..., description="ID of the parent document")
    content: str = Field(..., description="Text content of the chunk")
    embedding: Optional[VectorEmbedding] = Field(None, description="Vector embedding of the content")
    metadata: Metadata = Field(default_factory=dict, description="Chunk-specific metadata (e.g., position)")
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc), description="Timestamp of chunk creation")

# RAG Pipeline Models
class Query(BaseModel):
    """Represents a user query."""
    id: str = Field(..., description="Unique identifier for the query")
    text: str = Field(..., description="The user's query text")
    mode: RetrievalMode = Field(RetrievalMode.VECTOR, description="Desired retrieval mode")
    top_k: int = Field(5, description="Number of results to retrieve")
    filters: Optional[Metadata] = Field(None, description="Metadata filters for retrieval")

class RetrieverResult(BaseModel):
    """Holds the results from the retrieval step."""
    query_id: str = Field(..., description="ID of the original query")
    retrieved_chunks: List[Chunk] = Field(..., description="List of retrieved chunks")
    scores: Optional[List[float]] = Field(None, description="Relevance scores for each chunk")
    metadata: Metadata = Field(default_factory=dict, description="Metadata about the retrieval process")

class GeneratorContext(BaseModel):
    """Context provided to the LLM for generation."""
    query: Query = Field(..., description="The original user query")
    retrieved_context: RetrieverResult = Field(..., description="The chunks retrieved for context")

class GeneratorResponse(BaseModel):
    """Holds the final response generated by the LLM."""
    query_id: str = Field(..., description="ID of the original query")
    answer: str = Field(..., description="The generated answer text")
    context_used: List[str] = Field(..., description="List of chunk IDs used for generation")
    metadata: Metadata = Field(default_factory=dict, description="Metadata about the generation process") 